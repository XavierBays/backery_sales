# coding=utf-8
""" """
# Copyright 2023, Swiss Statistical Design & Innovation S√†rl

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import xgboost as xgb
from sklearn.linear_model import Lasso, LinearRegression
from sklearn.metrics import mean_absolute_error as mae
from sklearn.tree import DecisionTreeRegressor

st.set_page_config(
    page_title="Forecasting",
    page_icon="ü§ñ",
)

st.title('Pr√©disez !')

st.markdown("""
Nous disposons √† pr√©sent d'un ensemble de donn√©es nettoy√© et nous l'avons analys√©.
Nous sommes donc pr√™ts √† cr√©er des mod√®les et √† lancer des pr√©visions.
""")

st.divider()
st.header('S√©parer le jeu de donn√©es: train et test')

st.markdown("""
Selon le principe de base du machine learning, un mod√®le doit s'entra√Æner sur ensemble de donn√©es dit _train set_.
Celui-ci est construit en s√©lectionnant une partie des donn√©es pour l'apprentissage.

Les autres donn√©es non utilis√©es pour l'apprentissage sont dites de _test_.
Nous allons les utiliser pour comparer les r√©sultats de notre mod√®les et la r√©alit√© des ventes.

Il y a deux questions principales √† se poser au moment de s√©parer le jeu de donn√©es.
- Combien de donn√©es souhaite-t-on r√©server √† l'entrainement ? et √† la validation ?
- Comment s√©lectionnons-nous les donn√©es pour l'entra√Ænement ?

**Questions**:
- Pouvez-vous devinez l'effet du nombre de donn√©es utilis√©es pour l'entrainement ? (Pensez aux cas extr√™mes)
- Essayez d'imaginer diff√©rentes fa√ßons de s√©lectionner des donn√©es pour l'entra√Ænement.
""")

st.divider()

st.markdown("""
S√©lectionnez le **pourcentage** de donn√©es que vous souhaitez utiliser pour l'entrainement ainsi que la **m√©thodologie** de s√©paration des donn√©es.
""")


@st.cache_data
def load_data():
    df = pd.read_csv('data/bakery_sales_cleaned.csv')
    df['datetime'] = pd.to_datetime(df['datetime'])
    df.index = df['datetime']

    df = df.resample(rule='1D').sum()
    df['datetime'] = df.index
    df.index = range(len(df))

    df['year'] = df['datetime'].dt.year
    df['month'] = df['datetime'].dt.month
    df['day_of_week'] = df['datetime'].dt.day_of_week

    df['revenue_prev_day'] = df['full_price'].shift(1)
    df['quantity_prev_day'] = df['quantity'].shift(1)

    df['revenue_prev_week'] = df['full_price'].shift(7)
    df['quantity_prev_week'] = df['quantity'].shift(7)

    df = df.dropna(axis=0)

    return df


df = load_data()

perc_training = st.slider(
    "Pourcentage des donn√©es d'entrainement", 0, 100, 50)
split_methodo = st.selectbox(
    "M√©thodologie pour s√©parer les donn√©es:",
    ['testing after training', 'testing before training', 'random'],
    label_visibility='visible',
)

if split_methodo == 'random':
    df['train'] = np.random.rand(len(df)) <= perc_training/100
elif split_methodo == 'testing after training':
    df['train'] = df.index <= perc_training/100*len(df)
elif split_methodo == 'testing before training':
    df['train'] = ~(df.index <= (1-perc_training/100)*len(df))

df['Split'] = df['train'].apply(lambda x: 'Train' if x else 'Test')

color_discrete_map = {'Train': '#636EFA',
                      'Test': '#EF553B', 'Predicted': '#00CC96'}

fig = go.Figure()
fig.add_trace(go.Scatter(x=df[df['train']]['datetime'], y=df[df['train']]
                         ['full_price'], mode='markers', name='Train data', marker_color='#636EFA'))
fig.add_trace(go.Scatter(x=df[~df['train']]['datetime'], y=df[~df['train']]
                         ['full_price'], mode='markers', name='Test data', marker_color='#EF553B'))
fig.update_layout(
    xaxis_title="Dates",
    yaxis_title="Revenue",
)
st.plotly_chart(fig, use_container_width=True)


with st.expander("Astuces"):
    st.markdown("""
- Dans le cas de s√©rie temporelles, il est g√©n√©ralement compliqu√© d'utiliser une m√©thode de s√©paration al√©atoire.
En effet, s'il existe une corr√©lation entre deux dates proches, votre mod√®le pourrait s'appuyer sur des donn√©es non disponibles dans un contexte r√©el pour r√©aliser sa pr√©diction.
- Dans une m√™me id√©e, utiliser des donn√©es plus r√©centes pour pr√©dire des donn√©es plus anciennes ne fait pas de sens dans ce contexte.
- Il existe des m√©thodes plus √©volu√©es de train/test dites de validation crois√©es.
- En pratique, nous r√©servons souvent 70 √† 90 pourcent des donn√©es pour l'entra√Ænement.
    """)

st.divider()

st.header('Entrainez un mod√®le et pr√©disez')

st.markdown("""
Pour entra√Æner un mod√®le de machine learning, vous devez g√©n√©ralement choisir les variables que vous utiliserez,
ainsi que le mod√®le que vous souhaitez entra√Æner.

Dans cet exemple, nous avons passablement all√©g√© la partie li√©es aux variables appel√©es _features engineering_.
Celle-ci consiste √† adapter, croiser et augmenter les variables pr√©sentes dans le jeu de donn√©es.

Nous vous passons √©galement l'√©tape de s√©lection des param√®tres du mod√®les car elle est assez technique.

Nous vous proposons ci-dessous de choisir le mod√®le ainsi que les variables  que vous souhaitez y mettre.
""")

features = st.multiselect(
    'Choisissez les variables:',
    ['year', 'month', 'day_of_week', 'quantity', 'revenue_prev_day',
        'quantity_prev_day', 'revenue_prev_week', 'quantity_prev_week'],
    ['day_of_week', 'month'])

ml_model = st.selectbox(
    "Choisissez le mod√®le de machine learning:",
    ['Linear Regression', 'Lasso', 'XGB', 'Decision Tree'],
    label_visibility='visible',
)

target = 'full_price'

X_train = df[df['train']][features]
y_train = df[df['train']][target]

X_test = df[~df['train']][features]
y_test = df[~df['train']][target]

if st.button('Train model', type='primary', use_container_width=True):

    if len(features) == 0:
        st.markdown("**Please choose at least one feature!**")
    else:

        if ml_model == 'Linear Regression':
            model = LinearRegression()
        elif ml_model == 'XGB':
            model = xgb.XGBRegressor(
                eta=0.1, gamma=5, max_depth=4, reg_lambda=0.2, reg_alpha=10, tree_method='exact')
        elif ml_model == 'Decision Tree':
            model = DecisionTreeRegressor()
        elif ml_model == 'Lasso':
            model = Lasso(alpha=0.5)

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=df[df['train']]['datetime'], y=df[df['train']]
                                 ['full_price'], mode='markers', name='Train data', marker_color='#636EFA'))
        fig.add_trace(go.Scatter(x=df[~df['train']]['datetime'], y=df[~df['train']]
                                 ['full_price'], mode='markers', name='Test data', marker_color='#EF553B'))
        fig.add_trace(go.Scatter(x=df[~df['train']]['datetime'], y=y_pred, mode='markers',
                                 marker_line_width=2, name='Predicted data', marker_color='#00CC96'))
        fig.update_layout(
            xaxis_title="Dates",
            yaxis_title="Revenue",
        )
        st.plotly_chart(fig, use_container_width=True)

        err_mae = mae(y_test, y_pred)

        st.markdown(f"""
        Vos pr√©dictions confront√©es √† la r√©alit√© enregistrent une erreur MAE: **{err_mae:.2f}**.

        Cela signigie qu'en moyenne, vous r√©alisez une erreur d'environ {err_mae:.0f} ‚Ç¨ par jour (en positif ou en n√©gatif).""")

        with st.expander("En savoir plus sur la MAE"):
            st.markdown("""
            Mean Absolute Error:            
            Cette erreur correspond √† la somme de la valeur absolue des diff√©rences entre la valeur pr√©dite et la r√©alit√©.
                        """)

        st.markdown("""    

       L'√©tape suivante consiste √† r√©pondre √† certaines des questions suivantes et √† revenir au d√©but de cette page pour am√©liorer les performances du mod√®le :
        - √ätes-vous satisfait de vos r√©sultats ? 
        - Pouvez-vous expliquer pourquoi vous avez obtenu ces r√©sultats ? 
        - Avez-vous des id√©es pour am√©liorer le mod√®le ? 

        **D√©fi:** Notez votre score, changez les param√®tres et trouvez un meilleure mod√®le que vos coll√®gues!
        """)

with st.expander("Astuce"):
    st.markdown("""
Vous souhaitez en savoir plus sur un des mod√®les ? N'h√©sitez pas √† consulter Chat GPT ou Wikip√©dia qui est une source riche sur le sujet.
""")

st.divider()

st.header('Notes et remarques finales')
st.markdown("""
- Il est possible de choisir une autre fonction d'erreur.
Pour cela, il faut discuter avec les experts m√©tiers qui vous donneront leurs ressentis sur les erreurs les plus graves.
- Un grand d√©fi dans le cadre d'analyse de s√©ries temporelles est de n'utiliser que des donn√©es r√©ellement disponibles au temps t.
    """)

st.divider()

st.header('**F√©licitations**!')
st.markdown("""
Vous voici arriv√© au terme de cette analyse guid√©e.
Nous esp√©rons que cette exp√©rience vous aura plu et que vous comprenez dor√©nvant mieux ce qui se passe dans la t√™te d'un data scientist.

Si vous souhaitez en savoir plus sur le sujet, n'h√©sitez pas √† prendre contact avec nous sur notre
[page web.](https://swiss-sdi.ch/contact-swiss-sdi/)

Merci de nous avoir accompagn√© lors de cette analyse et √† bient√¥t!
    """)
